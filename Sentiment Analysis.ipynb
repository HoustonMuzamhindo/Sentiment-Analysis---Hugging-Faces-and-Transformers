{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d4c9a5-cada-44eb-a136-3a4019c47019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c0b9b9-cae5-4e17-a940-32812ecda021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e0f98b-6f38-4d41-b3d6-aa260fee5da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (C:\\Users\\hp\\.cache\\huggingface\\datasets\\tweet_eval\\emotion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c889007047d14f7db448c53d27c93763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load twitter evaluation dataset from huggging face hub\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"tweet_eval\", \"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "568fa35f-25ab-4d45-a0f4-74cea6c45f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 3257\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1421\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 374\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#see some dataset details\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b273426c-be9c-4fe7-9a33-60c3894016cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 3257\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#selecting the training dataset\n",
    "train = dataset[\"train\"]\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db521985-66b5-442b-b3be-0791107ea792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=4, names=['anger', 'joy', 'optimism', 'sadness'], id=None)}\n"
     ]
    }
   ],
   "source": [
    "#see the train features\n",
    "print(train.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4b892ad-bdfc-4982-9094-a8a88c938fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert this to a pandas dataframe\n",
    "dataset.set_format(\"pandas\")\n",
    "train_df = pd.DataFrame(dataset[\"train\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "682e1de4-e71d-4efd-8efb-32b7830706bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Worry is a down payment on a problem you may ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No but that's so cute. Atsu was probably shy a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rooneys fucking untouchable isn't he? Been fuc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's pretty depressing when u hit pan on ur fa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  “Worry is a down payment on a problem you may ...      2\n",
       "1  My roommate: it's okay that we can't spell bec...      0\n",
       "2  No but that's so cute. Atsu was probably shy a...      1\n",
       "3  Rooneys fucking untouchable isn't he? Been fuc...      0\n",
       "4  it's pretty depressing when u hit pan on ur fa...      3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33642734-c5d4-4a07-92ff-fdfaa96872cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc9f6ee-d5a6-46b7-bdd1-02b7f76f0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the label inteers to corresponding label names\n",
    "def label_int2str(x):\n",
    "    return dataset[\"train\"].features[\"label\"].int2str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c086f2cf-361a-4b83-8d93-dd438c6bb778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the label name\n",
    "train_df[\"label_name\"] = train_df[\"label\"].apply(label_int2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9ac52f3-7cde-4e1f-984f-bfed41ea0441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Worry is a down payment on a problem you may ...</td>\n",
       "      <td>2</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No but that's so cute. Atsu was probably shy a...</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rooneys fucking untouchable isn't he? Been fuc...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's pretty depressing when u hit pan on ur fa...</td>\n",
       "      <td>3</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_name\n",
       "0  “Worry is a down payment on a problem you may ...      2   optimism\n",
       "1  My roommate: it's okay that we can't spell bec...      0      anger\n",
       "2  No but that's so cute. Atsu was probably shy a...      1        joy\n",
       "3  Rooneys fucking untouchable isn't he? Been fuc...      0      anger\n",
       "4  it's pretty depressing when u hit pan on ur fa...      3    sadness"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d70e3f0-91d1-452a-aee8-7eb39af8f32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "optimism     294\n",
       "joy          708\n",
       "sadness      855\n",
       "anger       1400\n",
       "Name: label_name, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of the labels and see how imbalanced it is\n",
    "train_df[\"label_name\"].value_counts(ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89ffe91b-2f51-4268-b98d-d5ddbbcaa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the dataset back to type that is suitable for HuggingFace tokenisers and models\n",
    "dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "418a6f7d-196c-4b8b-89f7-9c6243b8431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the three datasets: train, validation and test\n",
    "train = dataset[\"train\"]\n",
    "validation = dataset[\"validation\"]\n",
    "test = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e80038-27fd-485a-970f-39ba208982bb",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c6f2013-9743-4c30-96a3-633446b34695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#will be using the Distill-Bert model\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "\n",
    "#get the tokenizer associated with this model\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path = model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a519d9d-874e-4796-8bf3-a495599a859c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size is: 30522\n",
      "Model max lengh is: 512\n",
      "Model input names are: ['input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "#check important information about the tokeniser\n",
    "print(f\"Vocab size is: {tokenizer.vocab_size}\")\n",
    "print(f\"Model max lengh is: {tokenizer.model_max_length}\")\n",
    "print(f\"Model input names are: {tokenizer.model_input_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37618ddc-f4e2-4be3-9a02-26d85b2dfd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see if tokenizer is working\n",
    "text = \"This is an example of tokenization\"\n",
    "output = tokenizer(text)\n",
    "tokens = tokenizer.convert_ids_to_tokens(output['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bfa7202-1f46-4eb4-99d7-cffa8b08be96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized output: {'input_ids': [101, 2023, 2003, 2019, 2742, 1997, 19204, 3989, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "\n",
      "Tokenized tokens: ['[CLS]', 'this', 'is', 'an', 'example', 'of', 'token', '##ization', '[SEP]']\n",
      "\n",
      "Tokenzied text: [CLS] this is an example of tokenization [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokenized output: {output}\")\n",
    "print()\n",
    "print(f\"Tokenized tokens: {tokens}\")\n",
    "print()\n",
    "print(f\"Tokenzied text: {tokenizer.convert_tokens_to_string(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0598fe5c-8dc5-4a0a-89b1-8109f764abfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\hp\\.cache\\huggingface\\datasets\\tweet_eval\\emotion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343\\cache-04ef56d34ce54f9e.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626e7f43040642d6a0be7cb2612ce0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\hp\\.cache\\huggingface\\datasets\\tweet_eval\\emotion\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343\\cache-8b08a90b450f515e.arrow\n"
     ]
    }
   ],
   "source": [
    "#tokenize the entire dataset\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding = True, truncation = True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched = True, batch_size = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f26c3c1-8640-49fd-a8cc-1bb1b2d8bdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3257\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1421\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 374\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84a05129-0ca5-4176-ba19-eb3870f0cd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Worry is a down payment on a problem you may ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[101, 1523, 4737, 2003, 1037, 2091, 7909, 2006...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2026, 18328, 1024, 2009, 1005, 1055, 310...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No but that's so cute. Atsu was probably shy a...</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2053, 2021, 2008, 1005, 1055, 2061, 1014...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rooneys fucking untouchable isn't he? Been fuc...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 24246, 2015, 8239, 19662, 10875, 3085, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's pretty depressing when u hit pan on ur fa...</td>\n",
       "      <td>3</td>\n",
       "      <td>[101, 2009, 1005, 1055, 3492, 2139, 24128, 204...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  “Worry is a down payment on a problem you may ...      2   \n",
       "1  My roommate: it's okay that we can't spell bec...      0   \n",
       "2  No but that's so cute. Atsu was probably shy a...      1   \n",
       "3  Rooneys fucking untouchable isn't he? Been fuc...      0   \n",
       "4  it's pretty depressing when u hit pan on ur fa...      3   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 1523, 4737, 2003, 1037, 2091, 7909, 2006...   \n",
       "1  [101, 2026, 18328, 1024, 2009, 1005, 1055, 310...   \n",
       "2  [101, 2053, 2021, 2008, 1005, 1055, 2061, 1014...   \n",
       "3  [101, 24246, 2015, 8239, 19662, 10875, 3085, 3...   \n",
       "4  [101, 2009, 1005, 1055, 3492, 2139, 24128, 204...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a pandas df and see what's there now\n",
    "check_tokens = tokenized_dataset.copy()\n",
    "check_tokens_df = pd.DataFrame(check_tokens[\"train\"][:])\n",
    "check_tokens_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb034bf8-6333-4cdf-8dee-5d39168d93a1",
   "metadata": {},
   "source": [
    "### Training the text classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43fbc896-a80a-4445-9d0d-8cf698d94b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a44cad98c64be7b2734f6da581f858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_layer_norm', 'vocab_transform', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "num_labels = 4\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels = num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3499d61-8aeb-4361-82a5-4666cd7adea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed the proceeded token_ids into the model in batches and apply padding to make them same length\n",
    "batch_size = 64\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer = tokenizer, return_tensors = \"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8145a83c-f56b-43e5-9e0a-c680fb222d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now create the tensorflow datasets from tokenized dataset\n",
    "tf_train_dataset = tokenized_dataset[\"train\"].to_tf_dataset(\n",
    "    columns = [\"input_ids\", \"attention_mask\"],\n",
    "    label_cols = [\"label\"],\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = data_collator\n",
    ")\n",
    "\n",
    "tf_valid_dataset = tokenized_dataset[\"validation\"].to_tf_dataset(\n",
    "    columns = [\"input_ids\", \"attention_mask\"],\n",
    "    label_cols = [\"label\"],\n",
    "    shuffle = False,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1938db6-6cda-437a-b1ed-302797f0f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary imports for training\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8950c010-29e5-4ea6-8979-27e7c577707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizers.Adam(learning_rate = 5e-5),\n",
    "    loss = losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    metrics = metrics.SparseCategoricalAccuracy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff952eb9-c7ce-46cc-a38c-7af558b4f08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 739s 14s/step - loss: 0.9815 - sparse_categorical_accuracy: 0.6122 - val_loss: 0.6796 - val_sparse_categorical_accuracy: 0.7513\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 724s 14s/step - loss: 0.5222 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.6548 - val_sparse_categorical_accuracy: 0.7701\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 719s 14s/step - loss: 0.3060 - sparse_categorical_accuracy: 0.9041 - val_loss: 0.6633 - val_sparse_categorical_accuracy: 0.7861\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 738s 15s/step - loss: 0.1664 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.6889 - val_sparse_categorical_accuracy: 0.7888\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 762s 15s/step - loss: 0.0975 - sparse_categorical_accuracy: 0.9725 - val_loss: 0.8798 - val_sparse_categorical_accuracy: 0.7513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f702bd8cd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model for 5 epochs\n",
    "model.fit(tf_train_dataset,\n",
    "          validation_data = tf_valid_dataset,\n",
    "          epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59ad9bbb-9a49-4703-b12d-e1467c5c0244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.9897310733795166,\n",
       " 4.209113597869873,\n",
       " -1.9471944570541382,\n",
       " -0.4496954679489136]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model on some sentences\n",
    "outputs = model.predict(tokenizer(\"I am feeling very happy\")[\"input_ids\"])\n",
    "outputs[\"logits\"][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8691273-6fa7-4be7-937d-032ba9264e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#apply softmax and pick the label with the maximum probability\n",
    "import numpy as np\n",
    "\n",
    "label_int = np.argmax(tf.keras.layers.Softmax()(outputs[\"logits\"][0].tolist()))\n",
    "print(label_int.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc0ca02d-f826-4f90-99cc-7421c1a08d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n"
     ]
    }
   ],
   "source": [
    "print(label_int2str(label_int.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e08668-d38a-4ede-9113-d0fd0187d072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
